#

## What is a Hidden Markov Model?

A *Hidden Markov Model (HMM)* is a statistical model that is used to describe a system that evolves over time. The system is assumed to be a *Markov process*, which means that the future state of the system depends only on the current state and **not** on any of the previous states. The *"hidden"* part of the model refers to the fact that the state of the system is not directly observable, but can only be inferred from the observations that are made.

To introduce the idea simply knowledge about Markov Chains is required. If you are familiar with Markov Chains you can skip the next section.

This post is used a basis for future blog posts that utilize Hidden Markov Models. Please bear with me as I introduce the concept of Markov Chains first.

![Big Math Yapping](assets/images/blog/hidden-markov-models-and-why-you-should-know-it/little-busters-noumi-kudryavka.gif)

## Markov Chains

A *Markov Chain* is a stochastic process that moves from one state to another in a sequence of discrete time steps. The probability of moving from one state to another depends only on the current state and **not** on any of the previous states. This property is known as the *Markov property*. That means it can be seen as a *memoryless process*.

Let's introduce the concept first with an example. Consider a model where we look at a very simplified stock market. On any given day, the stock market model can be in one of three states:

1. **Bull Market** - *the market is rising.*
2. **Bear Market** - *the market is falling.*
3. **Stagnant Market** - *the market is neither rising nor falling.*

Then we need transition probabilities. Those are the probabilities of moving from one state to another. We assume the followuing fictive examples for this model:

If it's a Bull Market:

    70% chance it will stay a Bull Market the next day.
    20% chance it will shift to a Bear Market.
    10% chance it will shift to a Stagnant Market.

If it's a Bear Market:

    80% chance it will stay a Bear Market the next day.
    15% chance it will shift to a Bull Market.
    5% chance it will shift to a Stagnant Market.

If it's a Stagnant Market:

    50% chance it will stay a Stagnant Market the next day.
    25% chance it will shift to a Bull Market.
    25% chance it will shift to a Bear Market.

With all this information we can create a transition matrix. This matrix is a square matrix that describes the probabilities of moving from one state to another. In our example, the matrix would look like this:

$$
\begin{bmatrix}
    0.7 & 0.2 & 0.1 \\
    0.15 & 0.8 & 0.05 \\
    0.25 & 0.25 & 0.5
\end{bmatrix}
$$

which can be interpreted as follows using this table:

| From \ To | Bull Market | Bear Market | Stagnant Market |
|-----------|-------------|-------------|-----------------|
| Bull Market | 0.7 | 0.2 | 0.1 |
| Bear Market | 0.15 | 0.8 | 0.05 |
| Stagnant Market | 0.25 | 0.25 | 0.5 |

This matrix is called the *transition matrix* and is denoted by *A*. The rows of the matrix represent the current state of the system and the columns represent the next state of the system. The element in the *i*-th row and *j*-th column of the matrix represents the probability of moving from state *i* to state *j*.

### Calculation of the probability of a sequence of states in a Markov Chain

It is assumed that the previous example is used. The question is now: What is the probability of a sequence of states in a *Markov Chain*?

What is the probability that the stock market will be in a *Bull Market* for two days and then shift to a *Bear Market* on the third day?

To calculate this probability, we need to multiply the transition probabilities for each day. The probability of the stock market being in a *Bull Market* for two days and then shifting to a *Bear Market* on the third day is given by:

$$
P(\text{Bull Market, Bull Market, Bear Market}) =
$$
$$
P(\text{Bull Market}) \times P(\text{Bull Market} \rightarrow \text{Bull Market}) \times P(\text{Bull Market} \rightarrow \text{Bear Market})
$$

When we plug in the values from the transition matrix, we get:

$$
P(\text{Bull Market, Bull Market, Bear Market}) = 1 \times 0.7 \times 0.2 = 0.14
$$

This means that the probability of the stock market being in a *Bull Market* for two days and then shifting to a *Bear Market* on the third day is 0.14.

## Expanding the Markov Chain to a Hidden Markov Model

In a *Hidden Markov Model (HMM)*, we have an additional layer of complexity. In addition to the states of the system, we also have observations that are made at each time step. The observations are assumed to be generated by the underlying state of the system, but they are not directly observable. Instead, we can only observe the output of the system.

To illustrate this, let's expand the stock market example to an HMM. In this model, we have the same three states for the stock market:

1. **Bull Market** - *the market is rising.*
2. **Bear Market** - *the market is falling.*
3. **Stagnant Market** - *the market is neither rising nor falling.*

In addition to the states of the system, we also have observations that are made at each time step. The observations are assumed to be generated by the underlying state of the system, but they are not directly observable. Instead, we can only observe the output of the system. In this case, the observations are the daily returns of the stock market:

1. **Positive Change** - *the market is rising.*
2. **Negative Change** - *the market is falling.*
3. **No Change** - *the market is neither rising nor falling.*

The transition probabilities for the states of the system are the same as before:

| From \ To | Bull Market | Bear Market | Stagnant Market |
|-----------|-------------|-------------|-----------------|
| Bull Market | 0.7 | 0.2 | 0.1 |
| Bear Market | 0.15 | 0.8 | 0.05 |
| Stagnant Market | 0.25 | 0.25 | 0.5 |

or in matrix form:

$$
\begin{bmatrix}
    0.7 & 0.2 & 0.1 \\
    0.15 & 0.8 & 0.05 \\
    0.25 & 0.25 & 0.5
\end{bmatrix}
$$

Now we need to define the emission probabilities. The emission probabilities describe the probability of observing a particular output given the underlying state of the system. In this case, the emission probabilities are the probabilities of observing a particular daily return given the state of the stock market:

| | Positive Change | Negative Change |
|-----------|-----------------|-----------------|
| Bull Market | 0.6 | 0.3 |
| Bear Market | 0.2 | 0.8 |
| Stagnant Market | 0.3 | 0.7 |

or in matrix form:

$$
\begin{bmatrix}
    0.6 & 0.3 \\
    0.2 & 0.8 \\
    0.3 & 0.7
\end{bmatrix}
$$

This matrix is called the *emission matrix* and is denoted by *B*. The rows of the matrix represent the states of the system and the columns represent the observations. The element in the *i*-th row and *j*-th column of the matrix represents the probability of observing the *j*-th output given the *i*-th state.

### Calculation of the probability of a sequence of states and observations in a Hidden Markov Model

The question is now: What is the probability of a sequence of states and observations in a *Hidden Markov Model*?

Let's assume that we observe the following daily returns for the stock market:

1. **Positive Change**
2. **Negative Change**
3. **Positive Change**

What is the probability that the stock market was in a *Bull Market* on the first day, shifted to a *Bear Market* on the second day, and then shifted back to a *Stagnant Market* on the third day, given these observations?

To calculate this probability, we need to consider both the transition probabilities and the emission probabilities. Step by step it looks like this:

1. Start in Bull Market:
    - $P(\text{Bull Market}) = 1$
    - $P(\text{Positive Change} \mid \text{Bull Market}) = 0.6$

2. Transition to Bear Market:
    - $P(\text{Bull Market} \rightarrow \text{Bear Market}) = 0.2$
    - $P(\text{Negative Change} \mid \text{Bear Market}) = 0.8$

3. Transition to Stagnant Market:
    - $P(\text{Bear Market} \rightarrow \text{Stagnant Market}) = 0.3$
    - $P(\text{Positive Change} \mid \text{Stagnant Market}) = 0.3$

Now we multiply all these probabilities together:
$$
P(\text{Bull Market, Bear Market, Stagnant Market, Positive Change, Negative Change, Positive Change}) =
$$
$$
1 \times 0.6 \times 0.2 \times 0.8 \times 0.05 \times 0.3 = 0.00144
$$

This means that the probability of the stock market being in a *Bull Market* on the first day, shifting to a *Bear Market* on the second day, and then shifting back to a *Stagnant Market* on the third day, given the observed daily returns, is 0.144%.

### Hidden Markov Models as a Graphical Model

Hidden Markov Models can be represented as a graphical model. The graphical model for an HMM consists of two types of nodes:

1. **State Nodes** - represent the states of the system.
2. **Observation Nodes** - represent the observations that are made at each time step.

The state nodes are connected to each other by directed edges that represent the transition probabilities between the states. The observation nodes are connected to the state nodes by directed edges that represent the emission probabilities of the observations given the states.

The graphical model for the stock market example would look like this:

![Hidden Markov Model Graphical Model](assets/images/blog/hidden-markov-models-and-why-you-should-know-it/HiddenMarkovModelStockMarket.png)

## Conclusion

In this blog post, we introduced the concept of a *Hidden Markov Model (HMM)*. We started by explaining the idea of a *Markov Chain* and how it is a stochastic process that moves from one state to another in a sequence of discrete time steps. We then expanded the concept to a *Hidden Markov Model* by introducing observations that are made at each time step. The observations are assumed to be generated by the underlying state of the system, but they are not directly observable.

In future blog posts, we will explore how to train an HMM using the *Baum-Welch algorithm* and how to use an HMM for tasks such as *part-of-speech tagging* and *speech recognition*. We will also explore topics like Viterbi algorithm to find the maximum a posteriori probability estimate of the most likely sequence of hidden states that results in a sequence of observed events.
